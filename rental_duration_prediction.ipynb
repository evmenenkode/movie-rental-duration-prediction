{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc10368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae077b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('rental_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3126fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime format\n",
    "df['rental_date'] = pd.to_datetime(df['rental_date'])\n",
    "df['return_date'] = pd.to_datetime(df['return_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb28cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rental length in days\n",
    "df['rental_lenght_days'] = (df['return_date'] - df['rental_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd625505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for special features\n",
    "df[\"deleted_scenes\"] = np.where(df[\"special_features\"].str.contains(\"Deleted Scenes\"), 1, 0)\n",
    "df[\"behind_the_scenes\"] = np.where(df[\"special_features\"].str.contains(\"Behind the Scenes\"), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba8fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['rental_date', 'return_date', 'special_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15fa1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop(columns='rental_lenght_days', axis=1)\n",
    "y = df['rental_lenght_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09207d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6edf24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaler, y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e876ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary regression models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43a602c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for each model\n",
    "model_parametrs = {\n",
    "    'LinearRegression': {},\n",
    "    'Ridge': {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1, 10]\n",
    "    },\n",
    "    'Lasso': {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1, 10]\n",
    "    },\n",
    "    'DecisionTreeRegressor': {\n",
    "        'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'n_estimators': [50, 100, 150, 200],\n",
    "        'max_depth': [None, 10, 20, 30]\n",
    "    },\n",
    "    'GradientBoostingRegressor': {\n",
    "        'n_estimators': [50, 100, 150, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.5]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e00255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    'Ridge': Ridge(),\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Lasso': Lasso(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c326d653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for Ridge\n",
      "Searching for LinearRegression\n",
      "Searching for Lasso\n",
      "Searching for DecisionTreeRegressor\n",
      "Searching for RandomForestRegressor\n",
      "Searching for GradientBoostingRegressor\n",
      "                   Model                                Best Params  Best MSE\n",
      "0                  Ridge                               {'alpha': 1}  2.849350\n",
      "1       LinearRegression                                         {}  2.849354\n",
      "2                  Lasso                           {'alpha': 0.001}  2.849414\n",
      "3  DecisionTreeRegressor  {'max_depth': 30, 'min_samples_split': 2}  2.305103\n",
      "4  RandomForestRegressor     {'max_depth': 20, 'n_estimators': 200}  2.088894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# List to store the results of the grid search\n",
    "models_list = []\n",
    "\n",
    "# Perform grid search for each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Searching for {model_name}\")\n",
    "    param_grid = model_parametrs[model_name]\n",
    "    \n",
    "    grid_search = GridSearchCV(model, param_grid, cv=4, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    best_mse = -grid_search.best_score_  # Take negative because GridSearchCV returns negative MSE\n",
    "    \n",
    "    models_list.append({'Model': model_name, 'Best Params': best_params, 'Best MSE': best_mse})\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "models_df = pd.DataFrame(models_list)\n",
    "print(models_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbe2f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize models with the best parameters found\n",
    "models = {\n",
    "    'Ridge': Ridge(alpha=models_df.loc[models_df['Model'] == 'Ridge', 'Best Params'].values[0]['alpha']),\n",
    "    'LinearRegression': LinearRegression(),  # No parameters to set for Linear Regression\n",
    "    'Lasso': Lasso(alpha=models_df.loc[models_df['Model'] == 'Lasso', 'Best Params'].values[0]['alpha']),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(\n",
    "        max_depth=models_df.loc[models_df['Model'] == 'DecisionTreeRegressor', 'Best Params'].values[0]['max_depth'],\n",
    "        min_samples_split=models_df.loc[models_df['Model'] == 'DecisionTreeRegressor', 'Best Params'].values[0]['min_samples_split']\n",
    "    ),\n",
    "    'RandomForestRegressor': RandomForestRegressor(\n",
    "        max_depth=models_df.loc[models_df['Model'] == 'RandomForestRegressor', 'Best Params'].values[0]['max_depth'],\n",
    "        n_estimators=models_df.loc[models_df['Model'] == 'RandomForestRegressor', 'Best Params'].values[0]['n_estimators']\n",
    "    ),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(\n",
    "        n_estimators=models_df.loc[models_df['Model'] == 'GradientBoostingRegressor', 'Best Params'].values[0]['n_estimators'],\n",
    "        learning_rate=models_df.loc[models_df['Model'] == 'GradientBoostingRegressor', 'Best Params'].values[0]['learning_rate']\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1873223e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge MSE: 2.941870616734153\n",
      "LinearRegression MSE: 2.9417238646975976\n",
      "Lasso MSE: 2.9417116642920518\n",
      "DecisionTreeRegressor MSE: 2.165347833153885\n",
      "RandomForestRegressor MSE: 2.031285398706584\n",
      "GradientBoostingRegressor MSE: 2.06977259149959\n",
      "Best Model: RandomForestRegressor(max_depth=20, n_estimators=200)\n",
      "Best MSE: 2.031285398706584\n"
     ]
    }
   ],
   "source": [
    "# Fit models and evaluate on test data\n",
    "best_mse = float('inf')\n",
    "best_model = None\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    print(f'{model_name} MSE: {mse}')\n",
    "    \n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_model = model\n",
    "\n",
    "# Output the best model and its MSE\n",
    "print(f'Best Model: {best_model}')\n",
    "print(f'Best MSE: {best_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee17e72d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
